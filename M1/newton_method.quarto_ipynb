{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"The Newton Method and its Applications\"\n",
        "page-layout: article\n",
        "jupyter: julia-1.11\n",
        "---"
      ],
      "id": "90bbcc3c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "include(\"activate.jl\")"
      ],
      "id": "667670e2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Newton method, also known as Newton-Raphson, is a powerful iterative technique widely used for solving nonlinear equations and optimization problems. In the context of nonlinear equations, the method seeks a root of a function $f(x) = 0$ by using the derivative information to iteratively refine an initial guess. For optimization, the method can be adapted to minimize a function by seeking the stationary points where its gradient vanishes. While Newton's method is highly efficient, requiring quadratic convergence under certain conditions, it also relies on the computation of derivatives, making it less suitable for some problems.\n",
        "\n",
        "To build up to Newton's method, we first introduce the [bisection method](https://en.wikipedia.org/wiki/Bisection_method). Unlike Newton's method, the bisection method does not require derivatives, making it an excellent starting point for understanding root-finding techniques. \n",
        "\n",
        "## The Bisection Method\n",
        "\n",
        "The bisection method is an iterative numerical technique for finding a root of a continuous function $f(x)$ on a closed interval $[a, b]$. The method assumes that $f(a)$ and $f(b)$ have opposite signs, which guarantees, by the Intermediate Value Theorem, that there is at least one root in $[a, b]$. The procedure works by repeatedly halving the interval and selecting the subinterval where the sign change occurs. \n",
        "\n",
        "### Exercise: Implement the Bisection Method\n",
        "\n",
        "1. **Objective**: Implement the bisection method in Julia and analyze its behavior.\n",
        "\n",
        "2. **Function Signature**: Define a function `bisection(f, a, b; tol=1e-12, max_iter=100)` that takes:\n",
        "   - A continuous function `f`.\n",
        "   - The interval bounds `a` and `b`.\n",
        "   - An optional tolerance `tol` for stopping criteria.\n",
        "   - An optional maximum number of iterations `max_iter`.\n",
        "\n",
        "The function should return:\n",
        "\n",
        "   - An approximation of the root.\n",
        "   - The number of iterations performed.\n",
        "\n",
        "3. **Example Problem**: Use the bisection method to find the root of $f(x) = \\cos(x) - x$ on the interval $[0, 1]$.\n",
        "\n",
        "4. **Analysis**:\n",
        "   - Record the approximate root at each iteration.\n",
        "   - Calculate the absolute error $|x_k - x^*|$ where $x^* = 0.7390851332151607$ is the true root.\n",
        "   - Plot the error on a logarithmic scale and determine the [order of convergence](https://en.wikipedia.org/wiki/Rate_of_convergence).\n",
        "\n",
        "5. **Discussion**:\n",
        "   - Observe the behavior of the error as the iterations progress.\n",
        "   - Conclude that the bisection method has a **linear convergence order**.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\" icon=false}\n",
        "### Hint for Implementation\n",
        "\n",
        "- Use a loop to halve the interval and check the signs of $f(a)$, $f(b)$, and $f(\\text{midpoint})$.\n",
        "- Stop the iterations when $|b - a| / 2 \\leq \\text{tol}$ or the maximum number of iterations is reached.\n",
        "- Handle cases where the initial interval does not satisfy the conditions for the method.\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\" icon=false}\n",
        "### Correction for the Bisection Method\n"
      ],
      "id": "99fd8e0d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function bisection(f, a, b; tol=1e-12, max_iter=100)\n",
        "    # Check if the initial interval is valid\n",
        "    if f(a) * f(b) > 0\n",
        "        error(\"The function must have opposite signs at the endpoints a and b.\")\n",
        "    end\n",
        "    \n",
        "    # Initialize variables\n",
        "    mid = (a + b) / 2\n",
        "    iter_count = 0\n",
        "    \n",
        "    while (b - a) / 2 > tol && iter_count < max_iter\n",
        "        iter_count += 1\n",
        "        mid = (a + b) / 2\n",
        "        \n",
        "        # Check if the midpoint is a root\n",
        "        if isapprox(f(mid), 0, atol=tol)\n",
        "            return mid, iter_count\n",
        "        elseif f(a) * f(mid) < 0\n",
        "            b = mid  # Root is in [a, mid]\n",
        "        else\n",
        "            a = mid  # Root is in [mid, b]\n",
        "        end\n",
        "    end\n",
        "    \n",
        "    # Return the midpoint as the approximate root\n",
        "    return mid, iter_count\n",
        "end\n",
        "\n",
        "# Example usage\n",
        "f(x) = cos(x) - x\n",
        "root, iterations = bisection(f, 0, 1)\n",
        "println(\"Approximate root: $root\")\n",
        "println(\"Evaluated function at the root: $(f(root))\")\n",
        "println(\"Number of iterations: $iterations\", \"\\n\")\n",
        "\n",
        "# Exact root for comparison\n",
        "exact_root = 0.7390851332151607\n",
        "println(\"Exact root: $exact_root\")\n",
        "println(\"Evaluated function at the exact root: $(f(exact_root))\")\n",
        "println(\"Absolute error: $(abs(root - exact_root))\")\n",
        "println(\"Relative error: $(abs(root - exact_root) / exact_root)\")"
      ],
      "id": "1aaf13fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\" icon=false}\n",
        "### Correction for Analysis\n",
        "\n",
        "To analyze the convergence of the bisection method for $f(x) = \\cos(x) - x$ on the interval $[0, 1]$, we compute the approximate root at each iteration and calculate the absolute error. Using the exact root $x^* \\approx 0.7390851332151607$, we determine the error $|x_k - x^*|$. We also plot the error on a logarithmic scale to observe the convergence behavior.\n",
        "\n",
        "Below is the Julia code for the analysis:\n"
      ],
      "id": "1c5f57e2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using Plots\n",
        "\n",
        "function bisection_analysis(f, a, b; tol=1e-12, max_iter=100, true_root=nothing)\n",
        "    if f(a) * f(b) > 0\n",
        "        error(\"The function must have opposite signs at the endpoints a and b.\")\n",
        "    end\n",
        "\n",
        "    midpoints = []\n",
        "    errors = []\n",
        "    iter_count = 0\n",
        "    mid = (a + b) / 2\n",
        "    \n",
        "    while (b - a) / 2 > tol && iter_count < max_iter\n",
        "        iter_count += 1\n",
        "        mid = (a + b) / 2\n",
        "        push!(midpoints, mid)\n",
        "        \n",
        "        if !isnothing(true_root)\n",
        "            push!(errors, abs(mid - true_root))\n",
        "        end\n",
        "\n",
        "        if isapprox(f(mid), 0, atol=tol)\n",
        "            break\n",
        "        elseif f(a) * f(mid) < 0\n",
        "            b = mid\n",
        "        else\n",
        "            a = mid\n",
        "        end\n",
        "    end\n",
        "    \n",
        "    return mid, iter_count, midpoints, errors\n",
        "end\n",
        "\n",
        "# Exact root for reference\n",
        "true_root = 0.7390851332151607\n",
        "f(x) = cos(x) - x\n",
        "root, iterations, midpoints, errors = bisection_analysis(f, 0, 1, true_root=true_root)\n",
        "\n",
        "# Print the approximate root and error\n",
        "println(\"Approximate root: $root\")\n",
        "println(\"Number of iterations: $iterations\")\n",
        "println(\"Final error: $(errors[end])\")\n",
        "\n",
        "# Plot the errors on a logarithmic scale\n",
        "plt = plot(1:iterations, errors, yscale=:log10, xlabel=\"Iteration\", ylabel=\"Absolute Error\", \n",
        "    title=\"Convergence of the Bisection Method\", label=\"Computed Error\")\n",
        "\n",
        "# Compute by linear regression the convergence rate\n",
        "using Polynomials\n",
        "line = fit(1:iterations, log10.(errors), 1)\n",
        "println(\"Convergence rate: $(10^(line.coeffs[2]))\")\n",
        "\n",
        "# add the linear regression line to the plot\n",
        "plot!(plt, 1:iterations, 10 .^ line.(1:iterations), label=\"Linear Regression\")"
      ],
      "id": "2344c163",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "\n",
        "## The Newton Method\n",
        "\n",
        "The **Newton Method**, or **Newton-Raphson Method**, is an iterative numerical technique for finding roots of a nonlinear equation $f(x) = 0$. Unlike the bisection method, Newton's method leverages the derivative of $f(x)$ to achieve a much faster rate of convergence under suitable conditions. Specifically, it exhibits **quadratic convergence**, meaning the number of accurate decimal places roughly doubles at each iteration once close to the root.\n",
        "\n",
        "### Newton's Iteration Formula\n",
        "\n",
        "Given an initial guess $x_0$, the Newton iteration is defined as:\n",
        "\n",
        "$$\n",
        "x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)},\n",
        "$$\n",
        "\n",
        "where $f'(x_k)$ is the derivative of $f(x)$ evaluated at $x_k$. The method relies on the approximation of $f(x)$ by its tangent line at $x_k$. The next iterate $x_{k+1}$ is where this tangent line intersects the $x$-axis.\n"
      ],
      "id": "16373eb3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using LinearAlgebra\n",
        "using Plots\n",
        "\n",
        "# Function illustrating the Newton method for solving nonlinear equations\n",
        "function illustration_newton(f::Function, df::Function, x0::Real, x_sol::Real, max_iter::Integer,\n",
        "    a::Real, b::Real, \n",
        "    f_xlim::Tuple{Real, Real}, f_ylim::Tuple{Real, Real},\n",
        "    g_xlim::Tuple{Real, Real}, g_ylim::Tuple{Real, Real},\n",
        "    filename::String)\n",
        "\n",
        "    # Initial values\n",
        "    xk = x0\n",
        "    x_sol = [x_sol]  # Exact solution\n",
        "\n",
        "    # Store the iterations of the Newton method\n",
        "    xs = [xk]\n",
        "    errors = []\n",
        "\n",
        "    # Newton's method iteration\n",
        "    for iter in 1:max_iter\n",
        "        # Update the Newton step\n",
        "        xk = xk - f(xk) / df(xk)\n",
        "        push!(xs, xk)\n",
        "        push!(errors, abs(xk - x_sol))  # Error at each step\n",
        "\n",
        "        # Check for convergence\n",
        "        if abs(f(xk)) < 1e-12\n",
        "            break\n",
        "        end\n",
        "    end\n",
        "\n",
        "    N = length(xs)\n",
        "    \n",
        "    # Generate a range for plotting the function and its tangent lines\n",
        "    x_span = range(a, b, length=101)\n",
        "\n",
        "    # Define the function and its gradient for plotting\n",
        "    pf_style = (xlim=f_xlim, ylim=f_ylim, linewidth=2, label=\"f(x)\")\n",
        "    pf = plot(x_span, f, pf_style...)\n",
        "\n",
        "    # Plotting the gradient of the function\n",
        "    pg_style = (xlim=g_xlim, ylim=g_ylim, linewidth=2, label=\"f'(x)\")\n",
        "    pg = plot(x_span, df, pg_style...)\n",
        "\n",
        "    # Compute the errors\n",
        "    erreur_style = (yaxis=:log, xlim=(-0.1, N-1+0.1), ylim=(minimum(errors)/2, 1), linewidth=2, label=\"Error\")\n",
        "    pe = plot(0:1:N-1, errors, erreur_style...)\n",
        "\n",
        "    # Set up plot styles\n",
        "    x_style = (color=:black, seriestype=:scatter, markersize=3, markerstrokewidth=0, label=\"\")\n",
        "    s_style = (color=:red, seriestype=:scatter, markersize=3, markerstrokewidth=0, label=\"\")\n",
        "    a_style = (color=:black, linestyle=:dash, label=\"\")\n",
        "    T_style = (color=:green, z_order=:back, label=\"\")\n",
        "    text_style = (annotationcolor=:black, annotationfontsize=10, annotationhalign=:center)\n",
        "\n",
        "    # Plot the Newton steps and the tangents\n",
        "    N_substeps = 3\n",
        "    ps = plot(pf, pg, pe, layout=(1, 3), size=(900, 400))\n",
        "\n",
        "    # Animation loop for visualizing the Newton method\n",
        "    anim = @animate for k = 0:1:(N_substeps * N)\n",
        "        if k == 0\n",
        "            plot!(ps[1], x_sol, [f(x_sol)], s_style...)  # Exact solution point\n",
        "            plot!(ps[2], x_sol, [0], s_style...)  # Gradient line at the solution\n",
        "        else\n",
        "            i, j = divrem(k-1, N_substeps)\n",
        "            x = xs[i + 1]\n",
        "            fx = f(x)\n",
        "            dfx = df(x)\n",
        "\n",
        "            # Draw point on the function\n",
        "            if j == 0\n",
        "                plot!(ps[1], x, [f(x)], x_style...)  # Function curve point\n",
        "                plot!(ps[2], x, [df(x)], x_style...)  # Gradient curve point\n",
        "\n",
        "                # Annotate the iteration number\n",
        "                x_str = \"x\" * string(i)\n",
        "                plot!(ps[1], annotation=((x, f(x), x_str)); annotationvalign=:top, text_style...)\n",
        "                plot!(ps[2], annotation=((x, 0, x_str)); annotationvalign=:bottom, text_style...)\n",
        "                \n",
        "                # Plot tangent line at current point\n",
        "                tangent(x) = f(x) + (x - xs[i]) * df(xs[i])\n",
        "                plot!(ps[1], x_span, tangent.(x_span), a_style...)  # Tangent line\n",
        "\n",
        "                # Plot error evolution\n",
        "                plot!(ps[3], [i], [errors[i+1]], x_style...)\n",
        "            elseif j == 1\n",
        "                plot!(ps[1], x, [f(x)], x_style...)  # Function curve point\n",
        "                plot!(ps[2], x, [df(x)], x_style...)  # Gradient curve point\n",
        "            else\n",
        "                # Plot the quadratic approximation\n",
        "                if i + 1 < N\n",
        "                    plot!(ps[1], x_span, f(xs[i]) + (x_span .- xs[i]) * df(xs[i]), T_style...)\n",
        "                end\n",
        "            end\n",
        "        end\n",
        "    end\n",
        "\n",
        "    plot!(ps)\n",
        "    gif(anim, filename, fps=1)\n",
        "end\n",
        "\n",
        "f(x) = cos(x) - x\n",
        "df(x) = -sin(x) - 1\n",
        "illustration_newton(f, df, 0.5, 0.7390851332151607, 10, -2, 2, (-2, 2), (-1, 1), (-2, 2), (-1, 1), \"newton_method.gif\")"
      ],
      "id": "095a163b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise: Apply Newton's Method to Find a Root\n",
        "\n",
        "1. **Objective**: Use the Newton method to find the root of $f(x) = \\cos(x) - x$, starting with the initial guess $x_0 = 0$.\n",
        "\n",
        "2. **Function Signature**: Define a function `newton(f, df, x0; tol=1e-12, max_iter=100)` that takes:\n",
        "   - A continuous function `f`.\n",
        "   - Its derivative `df`.\n",
        "   - The initial guess `x0`.\n",
        "   - An optional tolerance `tol` for stopping criteria.\n",
        "   - An optional maximum number of iterations `max_iter`.\n",
        "\n",
        "The function should return:\n",
        "\n",
        "   - The approximate root.\n",
        "   - The number of iterations performed.\n",
        "\n",
        "3. **Example Problem**: Use the Newton method to find the root of $f(x) = \\cos(x) - x$ with $f'(x) = -\\sin(x) - 1$ starting at $x_0 = 0$.\n",
        "\n",
        "4. **Analysis**:\n",
        "   - Record the approximate root at each iteration.\n",
        "   - Calculate the absolute error $|x_k - x^*|$ where $x^* \\approx 0.7390851332151607$ is the true root.\n",
        "   - Plot the error on a logarithmic scale and determine the **order of convergence**.\n",
        "\n",
        "::: {.callout-tip collapse=\"true\" icon=false}\n",
        "### Hint for Implementation\n",
        "\n",
        "- Use the Newton iteration formula to update the guess at each iteration.\n",
        "- Stop the iterations when $|x_{k+1} - x_k| \\leq \\text{tol}$ or the maximum number of iterations is reached.\n",
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\" icon=false}\n",
        "### Correction for the Newton Method\n"
      ],
      "id": "4de004a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "function newton(f, df, x0; tol=1e-12, max_iter=100)\n",
        "    xk = x0\n",
        "    iter_count = 0\n",
        "\n",
        "    while iter_count < max_iter\n",
        "        iter_count += 1\n",
        "        x_next = xk - f(xk) / df(xk)\n",
        "\n",
        "        # Check if the difference is within the tolerance\n",
        "        if abs(x_next - xk) < tol\n",
        "            return x_next, iter_count\n",
        "        end\n",
        "\n",
        "        xk = x_next\n",
        "    end\n",
        "\n",
        "    return xk, iter_count\n",
        "end\n",
        "\n",
        "# Example usage\n",
        "f(x) = cos(x) - x\n",
        "df(x) = -sin(x) - 1\n",
        "x0 = 0\n",
        "root, iterations = newton(f, df, x0)\n",
        "\n",
        "println(\"Approximate root: $root\")\n",
        "println(\"Evaluated function at the root: $(f(root))\")\n",
        "println(\"Number of iterations: $iterations\", \"\\n\")\n",
        "\n",
        "# Exact root for comparison\n",
        "exact_root = 0.7390851332151607\n",
        "println(\"Exact root: $exact_root\")\n",
        "println(\"Evaluated function at the exact root: $(f(exact_root))\")\n",
        "println(\"Absolute error: $(abs(root - exact_root))\")\n",
        "println(\"Relative error: $(abs(root - exact_root) / exact_root)\")"
      ],
      "id": "e4b44e9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.callout-caution collapse=\"true\" icon=false}\n",
        "### Correction for Analysis\n",
        "\n",
        "To analyze the convergence of the Newton method for $f(x) = \\cos(x) - x$, we compute the approximate root at each iteration and calculate the absolute error. Using the exact root $x^* \\approx 0.7390851332151607$, we determine the error $|x_k - x^*|$. We also plot the error on a logarithmic scale to observe the convergence behavior.\n",
        "\n",
        "Below is the Julia code for the analysis:\n"
      ],
      "id": "e0a5cac1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "using Plots\n",
        "using Polynomials\n",
        "\n",
        "function newton_analysis(f, df, x0; tol=1e-12, max_iter=100, true_root=nothing)\n",
        "    xk = x0\n",
        "    iter_count = 0\n",
        "    approximations = []\n",
        "    errors = []\n",
        "\n",
        "    while iter_count < max_iter\n",
        "        iter_count += 1\n",
        "        x_next = xk - f(xk) / df(xk)\n",
        "        push!(approximations, x_next)\n",
        "\n",
        "        if !isnothing(true_root)\n",
        "            push!(errors, abs(x_next - true_root))\n",
        "        end\n",
        "\n",
        "        if abs(x_next - xk) < tol\n",
        "            break\n",
        "        end\n",
        "\n",
        "        xk = x_next\n",
        "    end\n",
        "\n",
        "    return approximations, errors\n",
        "end\n",
        "\n",
        "# Exact root for reference\n",
        "true_root = 0.7390851332151607\n",
        "f(x) = cos(x) - x\n",
        "df(x) = -sin(x) - 1\n",
        "x0 = 0\n",
        "approximations, errors = newton_analysis(f, df, x0, true_root=true_root)\n",
        "\n",
        "# Exclude zero values for quadratic fitting\n",
        "non_zero_errors = filter(e -> e > 0, errors)  # Only non-zero errors\n",
        "indices_non_zero = findall(e -> e > 0, errors)  # Indices of non-zero errors\n",
        "\n",
        "if length(non_zero_errors) > 2\n",
        "    # Fit a quadratic polynomial to the log of non-zero errors\n",
        "    p = fit(indices_non_zero, log10.(non_zero_errors), 2)  # Fit quadratic to log10 of errors\n",
        "    println(\"Quadratic fit: $p\")\n",
        "\n",
        "    # Replace zero errors with the values predicted by the quadratic fit\n",
        "    for i in 1:length(errors)\n",
        "        if errors[i] == 0\n",
        "            errors[i] = 10^p(i)  # Replace with the fitted value at the iteration\n",
        "        end\n",
        "    end\n",
        "end\n",
        "\n",
        "# Print the approximate root and error\n",
        "println(\"Approximate root: $(approximations[end])\")\n",
        "println(\"Final error: $(errors[end])\")\n",
        "\n",
        "# Create the plot\n",
        "plt = plot(1:length(errors), errors, yscale=:log10, xlabel=\"Iteration\", ylabel=\"Absolute Error\", \n",
        "    title=\"Convergence of the Newton Method\", label=\"Computed Error\")\n",
        "\n",
        "# Add the fitted quadratic to the plot\n",
        "iterations = 1:length(errors)\n",
        "fitted_values = 10 .^ p.(iterations)\n",
        "plot!(plt, iterations, fitted_values, label=\"Quadratic Fit\", linestyle=:dash)\n",
        "\n",
        "# Show the plot\n",
        "display(plt)"
      ],
      "id": "4081230c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::"
      ],
      "id": "d759d827"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "julia-1.11",
      "language": "julia",
      "display_name": "Julia 1.11.1",
      "path": "/Users/ocots/Library/Jupyter/kernels/julia-1.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}