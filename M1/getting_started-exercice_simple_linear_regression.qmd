---
title: "Exercise: Simple Linear Regression"
page-layout: article
jupyter: julia-1.11
---

```{julia}
#| echo: false
using Pkg
using Suppressor
@suppress begin
  Pkg.activate(".")
end
```

## Least Squares Regression Line

We propose a first exercise about [simple linear regression](https://en.wikipedia.org/wiki/Simple_linear_regression). The data are excerpted from this [example](https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/simple-linear-regression.html) and saved into [data.csv](data.csv). We propose an [ordinary least squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) formulation which is a type of [linear least squares](https://en.wikipedia.org/wiki/Linear_least_squares) method for choosing the unknown parameters in a linear regression model by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being observed) in the input dataset and the output of the (linear) function of the independent variable.

<img max-height="300px" style="float: right;" src="images/Linear_least_squares_example2.svg"/>

Given a set of $m$ data points $y_{1}$, $y_{2}$, $\dots$, $y_{m}$, consisting of experimentally measured values taken at $m$ values $x_{1}$, $x_{2}$, $\dots$, $x_{m}$ of an independent variable ($x_i$ may be scalar or vector quantities), and given a model function $y=f(x,\beta),$ with $\beta =(\beta_{1},\beta_{2},\dots ,\beta_{n})$, it is desired to find the parameters $\beta_j$ such that the model function "best" fits the data. In linear least squares, linearity is meant to be with respect to parameters $\beta_j$, so
$$
  f(x, \beta) = \sum_{j=1}^n \beta_j\, \varphi_j(x).
$$
In general, the functions $\varphi_j$ may be nonlinear. However, we consider linear regression, that is
$$
  f(x, \beta) = \beta_1 + \beta_2 x.
$$
Ideally, the model function fits the data exactly, so 
$$
  y_i = f(x_i, \beta)
$$
for all $i=1, 2, \dots, m$. This is usually not possible in practice, as there are more data points than there are parameters to be determined. The approach chosen then is to find the minimal possible value of the sum of squares of the residuals
$$
  r_i(\beta) = y_i - f(x_i, \beta), \quad i=1, 2, \dots, m
$$
so to minimize the function
$$
  S(\beta) = \sum_{i=1}^m r_i^2(\beta).
$$
In the linear least squares case, the residuals are of the form
$$
  r(\beta) = y - X\, \beta
$$
with $y = (y_i)_{1\le i\le m} \in \mathbb{R}^m$ and $X = (X_{ij})_{1\le i\le m, 1\le j\le n} \in \mathrm{M}_{mn}(\mathbb{R})$, where $X_{ij} = \varphi_j(x_i)$. Since we consider linear regression, the $i$-th row of the matrix $X$ is given by
$$
  X_{i[:]} = [1 \quad x_i].
$$
The objective function may be written
$$
  S(\beta) = {\Vert y - X\, \beta \Vert}^2
$$
where the norm is the usual $2$-norm. The solution to the linear least squares problem
$$
  \underset{\beta \in \mathbb{R}^n}{\mathrm{minimize}}\, {\Vert y - X\, \beta \Vert}^2
$$
is computed by solving the *normal equation*
$$
  X^\top X\, \beta = X^\top y,
$$
where $X^\top$ denotes the transpose of $X$.

## Questions

To answer the questions you need to import the following packages.

```{julia}
using DataFrames
using CSV
using Plots
```

You also need to download the csv file. Click on the following image.

<a href="data/introduction/data.csv" download>
  <img src="../assets/images/logo-csv-download.png" width="50">
</a>

1. Using the packages `DataFrames.jl` and `CSV.jl`, load the dataset from [data/introduction/data.csv](data/introduction/data.csv) and save the result into a variable named `dataset`.

```{julia}
#| code-fold: true
#| code-summary: "Show the answer"
path = "data/introduction/data.csv" # update depending on the location of your file
dataset = DataFrame(CSV.File(path))
```

::: {.callout-note}
Do not hesitate to visit the documentation of `CSV.jl` and `DataFrames.jl`.
:::

2. Using the package `Plot.jl`, plot the data. 

::: {.callout-caution collapse="true"}
## Hint

Use `names(dataset)` to get the list of data names. If `Time` is a name you can access to the associated data by `dataset.Time`.
:::

```{julia}
#| code-fold: true
#| code-summary: "Show the answer"
plt = plot(
  dataset.Time, 
  dataset.Mass,
  seriestype=:scatter, 
  legend=false, 
  xlabel="Time", 
  ylabel="Mass"
)
```

1. Create the matrix $X$, the vector $\beta$ and solve the normal equation with the operator [`Base.\`](https://tinyurl.com/juliadoc-base-backslash).

::: {.callout-caution collapse="true"}
## Hint

Use `ones(m)` to generate a vector of 1 of length $m$.
:::

```{julia}
#| code-fold: true
#| code-summary: "Show the answer"
m = length(dataset.Time)
X = [ones(m) dataset.Time]
y = dataset.Mass
β = X\y
```

4. Plot the linear model on the same plot as the data. Use the `plot!` function. See the [basic concepts for plotting](https://docs.juliaplots.org/stable/basics/#Basic-Concepts).

```{julia}
#| code-fold: true
#| code-summary: "Show the answer"
x = [5, 20]
y = β[1] .+ β[2]*x
plot!(plt, x, y)
```